{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset to Cosmos DB Azure Table API\n",
    "\n",
    "To install the Azure Cosmos DB API you need to run:\n",
    "\n",
    "<b>```pip install azure-cosmosdb-table```</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-cosmosdb-table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info:\n",
    "<br>https://github.com/Azure/azure-cosmos-python\n",
    "<br>https://docs.microsoft.com/en-us/azure/cosmos-db/sql-api-sdk-python\n",
    "<br>Examples:\n",
    "<br>https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/cosmos-db/table-storage-how-to-use-python.md\n",
    "\n",
    "\n",
    "<b>NOTE: in order to run this notebook you are expected to have already created a Azure Storage account and a Cosmos DB account provisioned with the Table API.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas to prepare dataset for import  \n",
    "\n",
    "We need to have pandas for this example, so let's make sure it is installed by running:  \n",
    "  \n",
    "<b>```pip install pandas```</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = '.\\\\Employee.csv' #change this if the AdventureWorks folder is not on the same location as the notebook.\n",
    "\n",
    "df = pd.read_csv(file,header=None,sep='\\t', encoding=\"utf-16\") #The file is codified in utf-16\n",
    "\n",
    "#Lets verify the results\n",
    "print(df.info(verbose=True))\n",
    "df.head() #Shows Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are missing the column names since the file did not contain the **headers**.\n",
    "Hence, lets modify the column names as they are mentioned in the original AdventureWorksOLTP setup script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"BusinessEntityID\",\n",
    "                \"NationalIDNumber\",\n",
    "                \"LoginID\",\n",
    "                \"OrganizationNode\",\n",
    "                \"OrganizationLevel\",\n",
    "                \"JobTitle\",\n",
    "                \"BirthDate\",\n",
    "                \"MaritalStatus\",\n",
    "                \"Gender\",\n",
    "                \"HireDate\",\n",
    "                \"SalariedFlag\",\n",
    "                \"VacationHours\",\n",
    "                \"SickLeaveHours\",\n",
    "                \"CurrentFlag\",\n",
    "                \"rowguid\",\n",
    "                \"ModifiedDate\"]\n",
    "\n",
    "#Checking the results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see a summary of the values to chose the best collumns for **PartitionKey** (look for more unique values in a column) and **RowKey**. We check for data distribution and we need to think what type of queries we are going to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JobTitle seems to be a good candidate for partition key and LoginID for row key.<br>\n",
    "Hence, lets replace the column names accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'JobTitle':'PartitionKey','LoginID':'RowKey'}, inplace= True)\n",
    "\n",
    "#Confirm results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleansing - The \"\\\\\" in the login will break JSON serialization, so we are going to replace it with \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RowKey = df.RowKey.str.replace(\"\\\\\",\"_\") #backslash may cause some issues in Json\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, data is ready to be imported!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Cosmos D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cosmosdb.table.tableservice as ats\n",
    "from azure.cosmosdb.table import Entity, EntityProperty, EdmType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Connecting to Cosmos DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to Azure Cosmos DB Table \n",
    "the_connection_string = \"PRIMARY CONNECTION STRING\"\n",
    "ts= ats.TableService(endpoint_suffix = \"table.cosmos.azure.com\", connection_string= the_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table='AWEmployees'\n",
    "if not ts.exists(table):\n",
    "    ts.create_table(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading table\n",
    "\n",
    "To make things easier we are only importing a few columns. \n",
    "\n",
    "We iterate throught the DataFrame and insert rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]-1):\n",
    "    row=Entity()\n",
    "    row.PartitionKey=EntityProperty(EdmType.STRING,df.PartitionKey[i])\n",
    "    row.RowKey=EntityProperty(EdmType.STRING, df.RowKey[i])\n",
    "    row.MaritalStatus=EntityProperty(EdmType.STRING,df.MaritalStatus[i])\n",
    "    row.Gender=EntityProperty(EdmType.STRING,df.Gender[i])\n",
    "    row.HireDate=EntityProperty(EdmType.STRING,df.HireDate[i])\n",
    "    row.VacationHours=EntityProperty(EdmType.INT32,int(df.VacationHours[i]))\n",
    "    row.SickLeaveHours = EntityProperty(EdmType.INT32,int(df.SickLeaveHours[i]))\n",
    "    \n",
    "    ts.insert_entity(table,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the table\n",
    "\n",
    "Query one entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ts.query_entities(table, filter=\"PartitionKey eq 'Chief Executive Officer'\")\n",
    "for r in results:\n",
    "    print(f\"LoginId={r.RowKey}, HireDate= {r.HireDate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query outputs several entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ts.query_entities(table, filter=\"HireDate gt '2010-01-01' and HireDate lt '2010-12-31'\")\n",
    "for r in results:\n",
    "    print(f\"LoginId = {r.RowKey}, JobTitle = {r.PartitionKey}, HireDate = {r.HireDate}, VacationHours = {r.VacationHours.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_row={\"PartitionKey\":\"Senior Tool Designer\",\"RowKey\":\"adventure-works_ovidiu0\",\"VacationHours\":10}\n",
    "ts.merge_entity(table, entity=update_row,if_match=\"*\") #if using update, we need to pass all properties. Merge only changes the properties provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this sample is much less than in than the previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ts.query_entities(table, filter=\"PartitionKey eq 'Senior Tool Designer' and RowKey eq 'adventure-works_ovidiu0'\")\n",
    "for r in results:\n",
    "    print(f\"LoginId = {r.RowKey}, JobTitle = {r.PartitionKey}, HireDate = {r.HireDate}, VacationHours = {r.VacationHours}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Group Transaction  (ETG)\n",
    "  \n",
    "Let's simulate an entity group transaction.  \n",
    "In this case, two employees agreed to trade some vacation time, so 5 hours will be decreased from one and those hours will be added to the other one.  \n",
    "**This has the same characteristics of a tipical ACID transaction. (Only with entities that live in the same partition)**\n",
    "\n",
    "In order to accomplish this we need to update the two employees allowances simultaneously through an ETG.  \n",
    "In this case this is only possible because the two employess share the same role (i.e. have the same PartitionKey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp1=ts.get_entity(table,\"Production Technician - WC60\",\"adventure-works_maciej0\")\n",
    "emp2=ts.get_entity(table,\"Production Technician - WC60\",\"adventure-works_michael7\")\n",
    "\n",
    "print(\"---INICIAL BALANCE---\")\n",
    "print(f\"Employee's '{emp1.RowKey}' Vacation Hours: {emp1.VacationHours.value}\")\n",
    "print(f\"Employee's '{emp2.RowKey}' Vacation Hours: {emp2.VacationHours.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp1.VacationHours.value = emp1.VacationHours.value-5\n",
    "emp2.VacationHours.value = emp2.VacationHours.value+5\n",
    "\n",
    "print(f\"Employee's '{emp1.RowKey}' new vacation allowance: {emp1.VacationHours.value}\")\n",
    "print(f\"Employee's '{emp2.RowKey}' new vacation allowance: {emp2.VacationHours.value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values above are not yet persisted in backend (it only exists in the notebook)\n",
    "\n",
    "We use **TableBatch** to define the 2 update operation in only one operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmosdb.table.tablebatch import TableBatch\n",
    "batch = TableBatch()\n",
    "\n",
    "batch.update_entity(emp1,if_match='*') #unconditional update\n",
    "batch.update_entity(emp2,if_match=emp2.etag) #optimistic concurrency\n",
    "\n",
    "ts.commit_batch(table, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp1=ts.get_entity(table,\"Production Technician - WC60\",\"adventure-works_maciej0\")\n",
    "emp2=ts.get_entity(table,\"Production Technician - WC60\",\"adventure-works_michael7\")\n",
    "\n",
    "print(\"---FINAL BALANCE---\")\n",
    "print(f\"Employee's '{emp1.RowKey}' Vacation Hours: {emp1.VacationHours.value}\")\n",
    "print(f\"Employee's '{emp2.RowKey}' Vacation Hours: {emp2.VacationHours.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.delete_entity(table,'Purchasing Assistant','adventure-works_annette0', if_match=\"*\")\n",
    "\n",
    "results = ts.query_entities(table, filter=\"PartitionKey eq 'Purchasing Assistant' and RowKey eq 'adventure-works_annette0'\")\n",
    "print(f\"Rows returned:{len(results.items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.delete_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
